{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "import patsy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Data Preprocessing\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "meta = pd.read_csv(\"106_total.csv\")\n",
    "lasso_min_selected = pd.read_csv(\"lmin_total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type correction\n",
    "meta['age'] = pd.to_numeric(meta['age'])\n",
    "meta['sex'] = meta['sex'].astype('category')\n",
    "meta['bmi'] = pd.to_numeric(meta['bmi'])\n",
    "meta['days'] = pd.to_numeric(meta['days'])\n",
    "meta['ID'] = meta['ID'].astype(str)\n",
    "\n",
    "# Train/Test Split (8:2)\n",
    "unique_ids = meta['ID'].unique()\n",
    "np.random.seed(12)\n",
    "train_ids = np.random.choice(unique_ids, size=int(len(unique_ids) * 0.8), replace=False)\n",
    "test_ids = np.setdiff1d(unique_ids, train_ids)\n",
    "\n",
    "train = meta[meta['ID'].isin(train_ids)].copy()\n",
    "test = meta[meta['ID'].isin(test_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Formula (Oxygen): oxygen ~ age + sex + IGLV3_25 + IGHV3_60 + IGHV3_20 + IGLV3_10 + IGHV3_47 + IGLV3_9 + IGLV2_23 + IGHV3_43 + VEGF_pg_ml_ + CXCL10_IP_10_CRG_2_pg_ml_ + CCL22_MDC_pg_ml_ + CXCL4_PF4_pg_ml_ + IGKV1_27 + TRAJ60 + IGLV5_45 + IL_18_IL_1F4_pg_ml_ + CXCL9_MIG_pg_ml_ + IGLV3_19 + IGKV3_20 + IGLV4_69 + Granzyme_A_pg_ml_ + IGHV7_34_1 + IL_5_pg_ml_ + IGLJ5 + IGLV7_43 + IGLV2_11 + CCL23_MPIF_1_pg_ml_ + TRAV18 + TRBV13 + IGHV1_45 + CCL4_MIP_1_beta_pg_ml_ + TRAV11 + IL_33_pg_ml_ + IGHV3_35 + TRAJ57 + uPAR_pg_ml_ + IGLV4_60 + IL_6_pg_ml_ + IGHV1_2 + IGLV3_1 + TRBV6_9 + IGLV8_61 + TRBV5_1 + IGLV2_8 + CD14_pg_ml_ + MICA_pg_ml_ + IGLJ7 + IGHV1_68 + IGLV9_49 + IGLV6_57 + TRBV7_6 + TRBV23_1 + TRAV28 + MMP_7_pg_ml_ + IGFBP_1_pg_ml_ + CXCL1_GRO_alpha_pg_ml_ + IGLV1_47 + IL_2_pg_ml_ + TRBV7_1 + IGLV1_44 + IGHV1_46 + IGLV1_51 + TRBV6_4 + IL_3_pg_ml_ + IGHV3_64 + MMP_3_pg_ml_ + M_CSF_pg_ml_ + TRAJ58 + CCL19_MIP_3_beta_pg_ml_ + IGHV3_25 + BDNF_pg_ml_ + TRAJ33 + IGKV1_39 + IGLV10_54 + TRBV5_3 + IGHV5_78 + BAFF_BLyS_TNFSF13B_pg_ml_ + IGHV2_26 + FABP4_A_FABP_pg_ml_ + TRAJ1 + IL_4_pg_ml_ + IGLV3_21 + IGKV2_30 + IGLVI_70 + CCL2_JE_MCP_1_pg_ml_ + IL_6R_alpha_pg_ml_ + TRAJ6 + TRBV5_7 + ICAM_1_CD54_pg_ml_ + IFN_gamma_pg_ml_ + IGLJ6 + time + time:IGLV3_25 + time:IGHV3_60 + time:IGHV3_20 + time:IGLV3_10 + time:IGHV3_47 + time:IGLV3_9 + time:IGLV2_23 + time:IGHV3_43 + time:VEGF_pg_ml_ + time:CXCL10_IP_10_CRG_2_pg_ml_ + time:CCL22_MDC_pg_ml_ + time:CXCL4_PF4_pg_ml_ + time:IGKV1_27 + time:TRAJ60 + time:IGLV5_45 + time:IL_18_IL_1F4_pg_ml_ + time:CXCL9_MIG_pg_ml_ + time:IGLV3_19 + time:IGKV3_20 + time:IGLV4_69 + time:Granzyme_A_pg_ml_ + time:IGHV7_34_1 + time:IL_5_pg_ml_ + time:IGLJ5 + time:IGLV7_43 + time:IGLV2_11 + time:CCL23_MPIF_1_pg_ml_ + time:TRAV18 + time:TRBV13 + time:IGHV1_45 + time:CCL4_MIP_1_beta_pg_ml_ + time:TRAV11 + time:IL_33_pg_ml_ + time:IGHV3_35 + time:TRAJ57 + time:uPAR_pg_ml_ + time:IGLV4_60 + time:IL_6_pg_ml_ + time:IGHV1_2 + time:IGLV3_1 + time:TRBV6_9 + time:IGLV8_61 + time:TRBV5_1 + time:IGLV2_8 + time:CD14_pg_ml_ + time:MICA_pg_ml_ + time:IGLJ7 + time:IGHV1_68 + time:IGLV9_49 + time:IGLV6_57 + time:TRBV7_6 + time:TRBV23_1 + time:TRAV28 + time:MMP_7_pg_ml_ + time:IGFBP_1_pg_ml_ + time:CXCL1_GRO_alpha_pg_ml_ + time:IGLV1_47 + time:IL_2_pg_ml_ + time:TRBV7_1 + time:IGLV1_44 + time:IGHV1_46 + time:IGLV1_51 + time:TRBV6_4 + time:IL_3_pg_ml_ + time:IGHV3_64 + time:MMP_3_pg_ml_ + time:M_CSF_pg_ml_ + time:TRAJ58 + time:CCL19_MIP_3_beta_pg_ml_ + time:IGHV3_25 + time:BDNF_pg_ml_ + time:TRAJ33 + time:IGKV1_39 + time:IGLV10_54 + time:TRBV5_3 + time:IGHV5_78 + time:BAFF_BLyS_TNFSF13B_pg_ml_ + time:IGHV2_26 + time:FABP4_A_FABP_pg_ml_ + time:TRAJ1 + time:IL_4_pg_ml_ + time:IGLV3_21 + time:IGKV2_30 + time:IGLVI_70 + time:CCL2_JE_MCP_1_pg_ml_ + time:IL_6R_alpha_pg_ml_ + time:TRAJ6 + time:TRBV5_7 + time:ICAM_1_CD54_pg_ml_ + time:IFN_gamma_pg_ml_ + time:IGLJ6\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Feature Selection & Formula\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "features_o = lasso_min_selected['Oxygen'].dropna().astype(str).tolist()\n",
    "features_c = lasso_min_selected['CRP'].dropna().astype(str).tolist()\n",
    "features_u = lasso_min_selected['Urea'].dropna().astype(str).tolist()\n",
    "\n",
    "union_result = list(set(features_o) | set(features_c) | set(features_u))\n",
    "union_result = [x for x in union_result if x != \"\" and x != \"nan\"]\n",
    "\n",
    "exclude_vars = [\"(Intercept)\", \"Aldehyd.Dehydrogenase.1.A1.pg.ml.\"]\n",
    "ttt = [x for x in union_result if x not in exclude_vars]\n",
    "\n",
    "ttt = [x.replace('.', '_') for x in ttt]\n",
    "train.columns = train.columns.str.replace('.', '_')\n",
    "test.columns = test.columns.str.replace('.', '_')\n",
    "\n",
    "\n",
    "fixed_pred_base = [\"age\", \"sex\"]\n",
    "fixed_pred_base = [x.replace('.', '_') for x in fixed_pred_base]\n",
    "inter_pred = [x for x in ttt if x not in fixed_pred_base]\n",
    "\n",
    "def make_formula(dep_var, fixed_vars, inter_vars, all_vars):\n",
    "    fixed_part = \" + \".join(fixed_vars)\n",
    "    others = [v for v in all_vars if v not in fixed_vars]\n",
    "    if others:\n",
    "        fixed_part += \" + \" + \" + \".join(others)\n",
    "    \n",
    "    inter_part = \" + \".join([f\"time:{x}\" for x in inter_vars])\n",
    "    return f\"{dep_var} ~ {fixed_part} + time + {inter_part}\"\n",
    "\n",
    "form_o = make_formula(\"oxygen\", fixed_pred_base, inter_pred, ttt)\n",
    "form_c = make_formula(\"crp\", fixed_pred_base, inter_pred, ttt)\n",
    "form_u = make_formula(\"urea\", fixed_pred_base, inter_pred, ttt)\n",
    "\n",
    "print(f\"Generated Formula (Oxygen): {form_o}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. Manual Linear Mixed Model Class (수정됨)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class ManualLinearMixedModel:\n",
    "    def __init__(self, formula, data, group_col):\n",
    "        self.formula = formula\n",
    "        self.data = data\n",
    "        self.group_col = group_col\n",
    "        \n",
    "        self.y_df, self.X_df = patsy.dmatrices(formula, data, return_type='dataframe')\n",
    "        self.y = self.y_df.iloc[:, 0].values.flatten()\n",
    "        self.X = self.X_df.values\n",
    "        self.groups = data[group_col].values\n",
    "        self.unique_groups = np.unique(self.groups)\n",
    "        \n",
    "        self.p = self.X.shape[1]\n",
    "        \n",
    "        self.beta_hat = None\n",
    "        self.sigma_b_hat = None\n",
    "        self.sigma_e_hat = None\n",
    "        self.residuals = None\n",
    "        self.logLik = None\n",
    "        self.n_params = None\n",
    "\n",
    "    def neg_log_likelihood(self, params):\n",
    "        beta = params[:self.p]\n",
    "        sigma_b = np.exp(params[self.p])\n",
    "        sigma_e = np.exp(params[self.p + 1])\n",
    "        \n",
    "        nll = 0\n",
    "        for grp in self.unique_groups:\n",
    "            mask = (self.groups == grp)\n",
    "            y_i = self.y[mask]\n",
    "            X_i = self.X[mask]\n",
    "            n_i = len(y_i)\n",
    "            \n",
    "            resid = y_i - X_i @ beta\n",
    "            \n",
    "            # V_i = sigma_b^2 * J + sigma_e^2 * I\n",
    "            V_i = (sigma_b**2) * np.ones((n_i, n_i)) + (sigma_e**2) * np.eye(n_i)\n",
    "            \n",
    "            try:\n",
    "                sign, logdet = np.linalg.slogdet(V_i)\n",
    "                inv_V_resid = np.linalg.solve(V_i, resid)\n",
    "                quad_form = resid.T @ inv_V_resid\n",
    "                nll += 0.5 * (logdet + quad_form + n_i * np.log(2 * np.pi))\n",
    "            except np.linalg.LinAlgError:\n",
    "                return np.inf\n",
    "        return nll\n",
    "\n",
    "    def fit(self):\n",
    "        beta_init = np.linalg.lstsq(self.X, self.y, rcond=None)[0]\n",
    "        initial_params = np.concatenate([beta_init, [0.0, 0.0]])\n",
    "        result = minimize(self.neg_log_likelihood, initial_params, method='L-BFGS-B')\n",
    "        \n",
    "        self.opt_params = result.x\n",
    "        self.beta_hat = self.opt_params[:self.p]\n",
    "        self.sigma_b_hat = np.exp(self.opt_params[self.p])\n",
    "        self.sigma_e_hat = np.exp(self.opt_params[self.p + 1])\n",
    "\n",
    "        self.logLik = -result.fun\n",
    "        self.n_params = len(result.x)\n",
    "        \n",
    "        self.fitted_values = (self.X @ self.beta_hat).flatten()\n",
    "        self.residuals = (self.y - self.fitted_values).flatten() \n",
    "        \n",
    "        return result\n",
    "\n",
    "    def summary(self):\n",
    "        print(f\"Log-Likelihood: {-self.logLik:.2f}\")\n",
    "        print(f\"Random Effect SD (Sigma_b): {self.sigma_b_hat:.4f}\")\n",
    "        print(f\"Residual SD (Sigma_e): {self.sigma_e_hat:.4f}\")\n",
    "\n",
    "    def predict(self, newdata):\n",
    "        _, X_new = patsy.dmatrices(self.formula, newdata, return_type='dataframe')\n",
    "        return (X_new @ self.beta_hat).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4. Manual Joint Model Class\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class ManualJointModel:\n",
    "    def __init__(self, models_dict, data, group_col):\n",
    "        self.models_dict = models_dict\n",
    "        self.data = data\n",
    "        self.group_col = group_col\n",
    "        self.outcomes = list(models_dict.keys())\n",
    "        self.num_outcomes = len(self.outcomes)\n",
    "        self.y_list = []\n",
    "        self.X_list = []\n",
    "        self.beta_dims = [] \n",
    "        \n",
    "        self.groups = data[group_col].values\n",
    "        self.unique_groups = np.unique(self.groups)\n",
    "        \n",
    "        print(f\"Initializing Joint Model for {self.num_outcomes} outcomes...\")\n",
    "        print(f\"Target Structure: Correlation between {self.outcomes}\")\n",
    "        \n",
    "        for name in self.outcomes:\n",
    "            formula = models_dict[name]\n",
    "            y_df, X_df = patsy.dmatrices(formula, data, return_type='dataframe')\n",
    "            \n",
    "            self.y_list.append(y_df.iloc[:, 0].values)\n",
    "            self.X_list.append(X_df.values)\n",
    "            self.beta_dims.append(X_df.shape[1])\n",
    "            \n",
    "        # (1) Fixed Effects (Beta)\n",
    "        self.total_fixed_params = sum(self.beta_dims)\n",
    "        \n",
    "        # (2) Random Effects Covariance Matrix (D) - Unstructured\n",
    "        self.num_cov_params = self.num_outcomes * (self.num_outcomes + 1) // 2\n",
    "        \n",
    "        # (3) Residual Variances (Sigma_e)\n",
    "        self.num_resid_params = self.num_outcomes\n",
    "        self.total_params = self.total_fixed_params + self.num_cov_params + self.num_resid_params\n",
    "\n",
    "    def _unpack_params(self, params):\n",
    "        \"\"\"\n",
    "        최적화 파라미터를 Beta, D(Covariance), R(Residuals)로 분해\n",
    "        \"\"\"\n",
    "        curr = 0\n",
    "        \n",
    "        # 1. Fixed Effects (Betas)\n",
    "        betas = []\n",
    "        for dim in self.beta_dims:\n",
    "            betas.append(params[curr : curr + dim])\n",
    "            curr += dim\n",
    "            \n",
    "        # 2. Covariance Matrix D (Random Effects)\n",
    "        L_params = params[curr : curr + self.num_cov_params]\n",
    "        curr += self.num_cov_params\n",
    "        L = np.zeros((self.num_outcomes, self.num_outcomes))\n",
    "        indices = np.tril_indices(self.num_outcomes)\n",
    "        L[indices] = L_params\n",
    "        D = L @ L.T\n",
    "        \n",
    "        # 3. Residual Variances (log scale -> exp)\n",
    "        log_resid = params[curr:]\n",
    "        resid_sigmas = np.exp(log_resid)\n",
    "        \n",
    "        return betas, D, resid_sigmas\n",
    "\n",
    "    def neg_log_likelihood(self, params):\n",
    "        \"\"\"\n",
    "        Joint Negative Log-Likelihood 계산\n",
    "        \"\"\"\n",
    "        betas, D, resid_sigmas = self._unpack_params(params)\n",
    "        nll = 0\n",
    "        \n",
    "        for grp in self.unique_groups:\n",
    "            mask = (self.groups == grp)\n",
    "            n_i = np.sum(mask)\n",
    "            \n",
    "            # --- [1] Residual Vector (r_i) ---\n",
    "            resid_parts = []\n",
    "            for k in range(self.num_outcomes):\n",
    "                y_k = self.y_list[k][mask]\n",
    "                X_k = self.X_list[k][mask]\n",
    "                resid_parts.append(y_k - X_k @ betas[k])\n",
    "            \n",
    "            r_i = np.concatenate(resid_parts)\n",
    "            \n",
    "            # --- [2] Design Matrix for Random Effects (Z_i) ---\n",
    "            Z_i = np.zeros((n_i * self.num_outcomes, self.num_outcomes))\n",
    "            for k in range(self.num_outcomes):\n",
    "                row_start = k * n_i\n",
    "                row_end = (k + 1) * n_i\n",
    "                Z_i[row_start:row_end, k] = 1.0\n",
    "            \n",
    "            # --- [3] Construct Variance Matrix (V_i) ---\n",
    "            # V_i = Z_i * D * Z_i.T + R_i\n",
    "            R_blocks = [(resid_sigmas[k]**2) * np.eye(n_i) for k in range(self.num_outcomes)]\n",
    "            R_i = block_diag(*R_blocks)\n",
    "            V_i = Z_i @ D @ Z_i.T + R_i\n",
    "            \n",
    "            # --- [4] Log-Likelihood Calculation ---\n",
    "            try:\n",
    "                # Cholesky of V_i\n",
    "                L_Vi = np.linalg.cholesky(V_i)\n",
    "                logdet = 2 * np.sum(np.log(np.diag(L_Vi)))\n",
    "                # y = V^-1 * r\n",
    "                y_solve = np.linalg.solve(L_Vi, r_i)\n",
    "                quad_form = np.sum(y_solve**2)\n",
    "                nll += 0.5 * (logdet + quad_form)\n",
    "                \n",
    "            except np.linalg.LinAlgError:\n",
    "                return np.inf\n",
    "        \n",
    "        total_obs = len(self.data) * self.num_outcomes\n",
    "        nll += 0.5 * total_obs * np.log(2 * np.pi)\n",
    "        \n",
    "        return nll\n",
    "\n",
    "    def fit(self):\n",
    "        print(\"\\n[Step 1] Estimating Initial Parameters (OLS)...\")\n",
    "        init_betas = []\n",
    "        for k in range(self.num_outcomes):\n",
    "            b_ols = np.linalg.lstsq(self.X_list[k], self.y_list[k], rcond=None)[0]\n",
    "            init_betas.append(b_ols)\n",
    "        \n",
    "        x0_betas = np.concatenate(init_betas)\n",
    "        L_init = np.eye(self.num_outcomes)\n",
    "        indices = np.tril_indices(self.num_outcomes)\n",
    "        x0_cov = L_init[indices]\n",
    "        x0_resid = np.zeros(self.num_outcomes)\n",
    "        x0 = np.concatenate([x0_betas, x0_cov, x0_resid])\n",
    "        \n",
    "        print(\"[Step 2] Starting Joint Optimization (L-BFGS-B)...\")\n",
    "        print(\" -> Optimizing Correlations between Outcomes...\")\n",
    "        \n",
    "        result = minimize(self.neg_log_likelihood, x0, method='L-BFGS-B',\n",
    "                          options={'maxiter': 2000, 'disp': True})\n",
    "        \n",
    "        self.opt_params = result.x\n",
    "        self.logLik = -result.fun\n",
    "        self.aic = 2 * len(self.opt_params) - 2 * self.logLik\n",
    "        self.final_betas, self.final_D, self.final_resid_sigmas = self._unpack_params(self.opt_params)\n",
    "        \n",
    "        print(\"Optimization Completed.\")\n",
    "\n",
    "    def summary(self):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\" MANUAL JOINT MODEL RESULTS (Correlated Random Effects)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Log-Likelihood: {self.logLik:.4f}\")\n",
    "        print(f\"AIC: {self.aic:.4f}\")\n",
    "        print(\"\\n[1] Estimated Covariance Matrix (D):\")\n",
    "\n",
    "        D_df = pd.DataFrame(self.final_D, index=self.outcomes, columns=self.outcomes)\n",
    "        print(D_df)\n",
    "        print(\"\\n[2] Estimated Correlation Matrix:\")\n",
    "        \n",
    "        d_diag = np.sqrt(np.diag(self.final_D))\n",
    "        corr_matrix = self.final_D / np.outer(d_diag, d_diag)\n",
    "        corr_df = pd.DataFrame(corr_matrix, index=self.outcomes, columns=self.outcomes)\n",
    "        print(corr_df)\n",
    "        \n",
    "        print(\"\\n[3] Residual Standard Deviations (Sigma_e):\")\n",
    "        for k, name in enumerate(self.outcomes):\n",
    "            print(f\"  - {name}: {self.final_resid_sigmas[k]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test: Single Oxygen Model]\n",
      "Log-Likelihood: 328.81\n",
      "Random Effect SD (Sigma_b): 1.0000\n",
      "Residual SD (Sigma_e): 1.0000\n",
      "\n",
      "[Test: Single CRP Model]\n",
      "Log-Likelihood: 371.59\n",
      "Random Effect SD (Sigma_b): 1.0000\n",
      "Residual SD (Sigma_e): 1.0000\n",
      "\n",
      "[Test: Single Urea Model]\n",
      "Log-Likelihood: 802.77\n",
      "Random Effect SD (Sigma_b): 1.0000\n",
      "Residual SD (Sigma_e): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5. 실행 및 결과 확인 (Execution)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 5.1 개별 모델 테스트 (Oxygen)\n",
    "print(\"\\n[Test: Single Oxygen Model]\")\n",
    "model_o = ManualLinearMixedModel(form_o, train, group_col='ID')\n",
    "model_o.fit()\n",
    "model_o.summary()\n",
    "\n",
    "print(\"\\n[Test: Single CRP Model]\")\n",
    "model_c = ManualLinearMixedModel(form_c, train, group_col='ID')\n",
    "model_c.fit()\n",
    "model_c.summary()\n",
    "\n",
    "print(\"\\n[Test: Single Urea Model]\")\n",
    "model_u = ManualLinearMixedModel(form_u, train, group_col='ID')\n",
    "model_u.fit()\n",
    "model_u.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test: Joint Model with Covariance Structure]\n",
      "Initializing Joint Model for 3 outcomes...\n",
      "Target Structure: Correlation between ['oxygen', 'crp', 'urea']\n",
      "\n",
      "[Step 1] Estimating Initial Parameters (OLS)...\n",
      "[Step 2] Starting Joint Optimization (L-BFGS-B)...\n",
      " -> Optimizing Correlations between Outcomes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41471/2289036137.py:134: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "  result = minimize(self.neg_log_likelihood, x0, method='L-BFGS-B',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Completed.\n",
      "\n",
      "============================================================\n",
      " MANUAL JOINT MODEL RESULTS (Correlated Random Effects)\n",
      "============================================================\n",
      "Log-Likelihood: -1508.9884\n",
      "AIC: 4151.9769\n",
      "\n",
      "[1] Estimated Covariance Matrix (D):\n",
      "              oxygen           crp          urea\n",
      "oxygen  1.000000e+00 -5.101209e-12 -8.568044e-11\n",
      "crp    -5.101209e-12  1.000000e+00 -3.400255e-11\n",
      "urea   -8.568044e-11 -3.400255e-11  1.000000e+00\n",
      "\n",
      "[2] Estimated Correlation Matrix:\n",
      "              oxygen           crp          urea\n",
      "oxygen  1.000000e+00 -5.101209e-12 -8.568044e-11\n",
      "crp    -5.101209e-12  1.000000e+00 -3.400255e-11\n",
      "urea   -8.568044e-11 -3.400255e-11  1.000000e+00\n",
      "\n",
      "[3] Residual Standard Deviations (Sigma_e):\n",
      "  - oxygen: 1.0000\n",
      "  - crp: 1.0000\n",
      "  - urea: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Test: Joint Model with Covariance Structure]\")\n",
    "\n",
    "formulas = {\n",
    "    'oxygen': form_o,\n",
    "    'crp': form_c,\n",
    "    'urea': form_u\n",
    "}\n",
    "\n",
    "joint_model = ManualJointModel(formulas, train, group_col='ID')\n",
    "joint_model.fit()\n",
    "joint_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
